# AutoTranscript GUI ğŸ™ï¸

**AutoTranscript** is a powerful, GPU-accelerated subtitle generator built on top of OpenAI's Whisper model. It features both a **command-line interface (CLI)** and a beautiful **CustomTkinter-based GUI** for users who prefer a graphical workflow.

Supports:
- Languages such as: English, Chinese, Japanese, Korean.
- Local audio/video files.
- Translate or transcribe YouTube videos using only the link.
- Subtitle translation to English.
- OpenAI API (for higher quality translations) NOT AVAILABLE 

---

## âœ¨ Features

- ğŸ–¥ï¸ Full-featured **GUI with progress tracking**, real-time logs.
- ğŸ“œ Generate `.srt` subtitle files from media files
- ğŸŒ Supports multilingual transcription and optional **translation to English**
- ğŸ§  Uses [Faster-Whisper](https://github.com/guillaumekln/faster-whisper) for fast GPU-accelerated transcription

---
## YOUTUBE TUTORIAL IN SPANISH

(https://www.youtube.com/watch?v=dB6D1i1BjXc)

---
## ğŸ“¸ GUI Preview

> ![image](https://github.com/user-attachments/assets/d328dff2-4d82-485c-95b8-162405a3e856)

---

## ğŸ§© Requirements

- Python 
- NVIDIA GPU with CUDA (recommended)
- Visual C++ Redistributable 14

---
## Installation for Releases 

 - Extract the .rar file.
 - Go to the app folder.
 - At the top of the path bar, type cmd.
 - In the console, type: pip install -r requirements.txt.
 - Go back to the .bat file and run it.
---

## ğŸ“¦ Installation

```bash
git clone https://github.com/jjaruna/autoTranscriptGUI.git
cd autoTranscriptGUI
pip install -r requirements.txt
```
---

## ğŸš€ Launch the GUI

```bash
python AutoTranscriptGUI.py
```
### ğŸ” Whisper Model Comparison Summary

| Model               | VRAM (Min)    | âš™ï¸ Performance        | ğŸ¯ Use Case                                               | ğŸŒ Translate into English |
|--------------------|---------------|------------------------|-----------------------------------------------------------|--------------------------|
| `tiny`             | â‰¥ 1 GB        | âš¡ Very Fast            | Quick tests, low-resource devices                         | âœ…                        |
| `base`             | â‰¥ 2 GB        | âš¡ Fast                 | Simple transcriptions, short audio                        | âœ…                        |
| `small`            | â‰¥ 4 GB        | âš–ï¸ Balanced            | Decent accuracy and speed for general use                | âœ…                        |
| `medium`           | â‰¥ 8 GB        | ğŸ•’ Slower              | High-quality results for longer files                    | âœ…                        |
| `large-v1`         | â‰¥ 10 GB       | ğŸ¢ Slower              | Older but still strong performer                         | âœ…                        |
| `large-v2`         | â‰¥ 10 GB       | ğŸ¢ Slower              | More robust, especially with noisy inputs                | âœ…                        |
| `large-v3`         | â‰¥ 12 GB       | ğŸŒ Slowest             | Highest accuracy offline, latest version                 | âœ…                        |
| `large-v3-turbo`   | â‰¥ 8â€“10 GB     | âš¡ Fastest             | High-speed, high-accuracy, great multilingual support     | âŒ                        |


# ğŸ§  Recommendation

After testing the `large-v3-turbo` model more than 10 times, I can confidently say it is the **fastest** and **most accurate** among all Whisper models included in this app.

ğŸ–¥ï¸ My system has **4GB of VRAM**, and despite being under the recommended VRAM for large models, `large-v3-turbo` still performed exceptionally well.

âš ï¸ **Note:** Your experience may vary depending on your GPU and available VRAM. Use this recommendation as a reference, **not a guarantee**. If you encounter performance issues, try smaller models like `medium` or `small`.

---

## ğŸ–¥ï¸ CLI Mode (Optional)

You can still use the command-line version via `autosub.py`:

```bash
python autosub.py myvideo.mp4 -l ja --translate --model base
```

### CLI Options

| Option              | Description |
|---------------------|-------------|
| `filename`          | File path |
| `-l`, `--language`  | Force language (e.g. `en`, `es`, `zh`) |
| `-t`, `--translate` | Translate to English |
| `-o`, `--openai`    | Use OpenAI API |
| `--model`           | Whisper model to use |
| `--debug`           | Enable debug mode |
| `--keep`            | Keep intermediate WAV file |

---

## ğŸ“ Output

- Subtitles are saved as `.srt` files in the same folder as your media.
- If translated, original and translated text will be preserved.

---

## ğŸ§ª Example GUI Workflow

1. Open GUI
2. Select video/audio file
3. Choose language and Whisper model
4. (Optional) Enable "Translate to English"
5. Click **Start Transcription**

---

## ğŸ™ Credits

- Built with [OpenAI Whisper](https://github.com/openai/whisper)
- Powered by [Faster-Whisper](https://github.com/guillaumekln/faster-whisper)
- GUI built with [CustomTkinter](https://github.com/TomSchimansky/CustomTkinter)
- Thank you General Koi, for the great help in testing and reviewing the Japanese transcripts.

---

## ğŸ“„ License

MIT License â€” free for personal and commercial use.

